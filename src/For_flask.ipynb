{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "may be this might help to convert it into java script or use the code in back end\n",
    "\n",
    "find the saved model under \n",
    "\n",
    "\n",
    "\n",
    "https://towardsdatascience.com/how-to-deploy-tensorflow-models-to-the-web-81da150f87f7\n",
    "\n",
    "https://jameshfisher.com/2021/03/09/how-to-export-a-model-for-tensorflowjs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing dependencies \n",
    "!pip install numpy tensorflow cv2 object_detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# should run the below cell before detection\n",
    "\n",
    "configure these pathes Before running the cell below.\n",
    "\n",
    "PATH_TO_MODEL_DIR\n",
    "\n",
    "PATH_TO_LABELS\n",
    "\n",
    "ONE_IMAGE_PATH\n",
    "\n",
    "PATH_2_SAVE_ANNOTED_PIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.utils import label_map_util\n",
    "import time\n",
    "import argparse\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging (1)\n",
    "warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "# PROVIDE PATH TO IMAGE DIRECTORY\n",
    "# IMAGE_PATHS = '/content/training_demo/images/train/image1.jpg'\n",
    "# IMAGE_PATHS = 'C:/Maha/dev/Temp/PHD_FYP_TEMP/TensorFlow/workspace/training_demo/images/test/37.JPEG'\n",
    "\n",
    "# PROVIDE PATH TO MODEL DIRECTORY\n",
    "# PATH_TO_MODEL_DIR = '/content/training_demo/exported_models/my_model'\n",
    "PATH_TO_MODEL_DIR = 'C:/Maha/dev/Temp/PHD_FYP_TEMP/TensorFlow/workspace/training_demo/exported-models/my_model'\n",
    "\n",
    "# PROVIDE PATH TO LABEL MAP\n",
    "# PATH_TO_LABELS = '/content/training_demo/annotations/label_map.pbtxt'\n",
    "PATH_TO_LABELS = 'C:/Maha/dev/Temp/PHD_FYP_TEMP/TensorFlow/workspace/training_demo/annotations/label_map.pbtxt'\n",
    "\n",
    "# PROVIDE THE MINIMUM CONFIDENCE THRESHOLD\n",
    "MIN_CONF_THRESH = float(0.60)\n",
    "\n",
    "# LOAD THE MODEL\n",
    "PATH_TO_SAVED_MODEL = PATH_TO_MODEL_DIR + \"/saved_model\"\n",
    "\n",
    "print('Loading model...', end='')\n",
    "start_time = time.time()\n",
    "\n",
    "# LOAD SAVED MODEL AND BUILD DETECTION FUNCTION\n",
    "detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print('Done! Took {} seconds'.format(elapsed_time))\n",
    "\n",
    "# LOAD LABEL MAP DATA FOR PLOTTING\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
    "                                                                    use_display_name=True)\n",
    "\n",
    "\n",
    "def load_image_into_numpy_array(path):\n",
    "    \"\"\"Load an image from file into a numpy array.\n",
    "    Puts image into numpy array to feed into tensorflow graph.\n",
    "    Note that by convention we put it into a numpy array with shape\n",
    "    (height, width, channels), where channels=3 for RGB.\n",
    "    Args:\n",
    "    path: the file path to the image\n",
    "    Returns:\n",
    "    uint8 numpy array with shape (img_height, img_width, 3)\n",
    "    \"\"\"\n",
    "    return np.array(Image.open(path))\n",
    "\n",
    "\n",
    "def generate_result(IMAGE_PATHS):\n",
    "    print('Running inference for {}... '.format(IMAGE_PATHS), end='')\n",
    "    image = cv2.imread(IMAGE_PATHS)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image_expanded = np.expand_dims(image_rgb, axis=0)\n",
    "\n",
    "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "    input_tensor = tf.convert_to_tensor(image)\n",
    "    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
    "    input_tensor = input_tensor[tf.newaxis, ...]\n",
    "\n",
    "    # input_tensor = np.expand_dims(image_np, 0)\n",
    "    detections = detect_fn(input_tensor)\n",
    "\n",
    "    # All outputs are batches tensors.\n",
    "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "    # We're only interested in the first num_detections.\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(\n",
    "        np.int64)\n",
    "\n",
    "    image_with_detections = image.copy()\n",
    "\n",
    "    # SET MIN_SCORE_THRESH BASED ON YOU MINIMUM THRESHOLD FOR DETECTIONS\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "        image_with_detections,\n",
    "        detections['detection_boxes'],\n",
    "        detections['detection_classes'],\n",
    "        detections['detection_scores'],\n",
    "        category_index,\n",
    "        use_normalized_coordinates=True,\n",
    "        max_boxes_to_draw=200,\n",
    "        min_score_thresh=0.5,\n",
    "        agnostic_mode=False)\n",
    "\n",
    "    print('Done')\n",
    "    return image_with_detections\n",
    "    # # DISPLAYS OUTPUT IMAGE\n",
    "    # cv2.imshow(\"TEST\",image_with_detections)\n",
    "    # cv2.waitKey(0)\n",
    "    # # CLOSES WINDOW ONCE KEY IS PRESSED\n",
    "\n",
    "    # cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "path = 'C://Maha//dev//Github//PHD_FYP//Dataset//train//potholes//'\n",
    "list_files = []\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        list_files.append(os.path.join(root, file))\n",
    "path = 'C://Maha//dev//Github//PHD_FYP//Dataset//train//normal//'\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        list_files.append(os.path.join(root, file))\n",
    "path = 'C://Maha//dev//Temp//PHD_FYP_TEMP//TensorFlow//workspace//training_demo//images//test//'\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        list_files.append(os.path.join(root, file))\n",
    "\n",
    "images_test_ = [l for l in list_files if l.endswith('.JPEG')]\n",
    "\n",
    "PATH_2_SAVE_ANNOTED_PIC='C://Maha//dev//Temp//PHD_FYP_TEMP//TensorFlow//workspace//training_demo//images//result//Result'\n",
    "\n",
    "for img_name in images_test_:\n",
    "    try:\n",
    "        image_with_detections = generate_result(img_name)\n",
    "        isWritten = cv2.imwrite( PATH_2_SAVE_ANNOTED_PIC + img_name.split('//')[-1], image_with_detections)\n",
    "        if isWritten:\n",
    "            print('[+] Image is successfully saved as file.')\n",
    "    except Exception:\n",
    "        print('[-] ERR :', img_name)\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funtion To generate the result for single picture which will be specified in ONE_IMAGE_PATH variable.\n",
    "\n",
    "From second picture onwards, only the below code will be enough to run.\n",
    "\n",
    "Configure above code accordingly to run it only once, and bewlow code any number of times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_2_SAVE_ANNOTED_PIC='C://Maha//dev//Temp//PHD_FYP_TEMP//TensorFlow//workspace//training_demo//images//result//Result'\n",
    "ONE_IMAGE_PATH = \"C:/Maha/dev/Temp/PHD_FYP_TEMP/TensorFlow/workspace/training_demo/images/test/37.JPEG\"\n",
    "\n",
    "def generate_result_for_one_img(ONE_IMAGE_PATH,PATH_2_SAVE_ANNOTED_PIC):\n",
    "    try:\n",
    "        image_with_detections = generate_result(ONE_IMAGE_PATH)\n",
    "        isWritten = cv2.imwrite(PATH_2_SAVE_ANNOTED_PIC + ONE_IMAGE_PATH.split('//')[-1], image_with_detections)\n",
    "        if isWritten:\n",
    "            print('[+] Image is successfully saved as file.')\n",
    "    except Exception:\n",
    "        print('[-] ERR :Could not save it', ONE_IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring paths and executing these lines is enough \n",
    "\n",
    "## but every time to load the model it takes time\n",
    "\n",
    "## do something about it or leave it "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PHD_FYP2_Kernel",
   "language": "python",
   "name": "phd_fyp2"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
